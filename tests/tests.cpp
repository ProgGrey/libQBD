/*
 * Copyright (c) 2022 Sergey Astaf'ev, IAMR Karelian Research Centre of the RAS
 * All rights reserved.
 *
 * This source code is licensed under the BSD-3 clause license.
 */
#define EIGEN_FAST_MATH 1
#include "../inc/libQBD.hpp"

#define BOOST_TEST_MODULE main_test_module
#define BOOST_TEST_MAIN
#define BOOST_TEST_DYN_LINK
#include <boost/test/unit_test.hpp>
#include <iostream>

using namespace Eigen;
using namespace libQBD;
using namespace std;
using namespace libQBD::internal;

typedef Matrix<double, Dynamic, Dynamic> mMatr;

BOOST_AUTO_TEST_CASE(cluster_model_2_servers)
{
	const double p_h = 0.8;
	const double p_l = 0.8;
	const double p1 = 2.0/3.0;
	const double lambda = 0.99;
	const double f_l = 1;
	const double f_h = 2.2;
	const double mu1 = 1;
	const double mu2 = 2;
	

	// Zero level of model
	Matrix<double, 2, 4> A0_plus{
		{p1*(1-p_h), (1-p1)*(1-p_h), p1*p_h, p_h*(1-p1)},
		{0		   , 0			   , p1	   , 1 - p1}};

	A0_plus *= lambda;
	Matrix<double, 2, 2> A0_0 = (-(A0_plus.rowwise().sum())).asDiagonal();
	
	// First level of model 
	Matrix<double, 4, 2>  A1_minus{
		{f_l*mu1	, 0},
		{f_l*mu2	, 0},
		{f_h*p_l*mu1, f_h*(1-p_l)*mu1},
		{f_h*p_l*mu2, f_h*(1-p_l)*mu2}};

	Matrix<double, 4, 6> A1_plus{
		{p1*(1-p_h), (1-p1)*(1-p_h)		 , 0	, p1*p_h, p_h*(1-p1), 0},
		{0         , 0                   , 1-p_h, 0		, 0			, p_h},
		{0         , 0					 , 0	, p1	, 1 - p1	, 0},
		{0         , 0					 , 0    , 0		, 0			, 1}};
	A1_plus *= lambda;

	Matrix<double, 4, 4> A1_0 = (-(A1_minus.rowwise().sum() +
								   A1_plus.rowwise().sum())).asDiagonal();

	// Second level of model
	Matrix<double, 6, 4>  A2_minus{
		{2*f_l*mu1     , 0				   , 0				   , 0},
		{0			   , f_l*mu1		   , 0				   , 0},
		{f_l*p1*mu2	   , f_l*(1-p1)*mu2	   , 0				   , 0},
		{2*f_h*p_l*mu1 , 0				   , 2*f_h*(1-p_l)*mu1 , 0},
		{0			   , f_h*p_l*mu1	   , 0				   , f_h*(1-p_l)*mu1},
		{f_h*p_l*p1*mu2, f_h*p_l*(1-p1)*mu2, f_h*(1-p_l)*p1*mu2, f_h*(1-p_l)*(1-p1)*mu2}};

	Matrix<double, 6, 6> A2_plus{
		{1-p_h, 0	 , 0    , p_h, 0  , 0},
		{0	  , 1-p_h, 0    , 0  , p_h, 0},
		{0	  , 0	 , 1-p_h, 0  , 0  , p_h},
		{0	  , 0	 , 0    , 1  , 0  , 0},
		{0	  , 0	 , 0    , 0  , 1  , 0},
		{0	  , 0	 , 0    , 0  , 0  , 1}};
	A2_plus *= lambda;

	/*
	Matrix<double, 6, 6> A2_0 = (-(A2_minus.rowwise().sum() +
		A2_plus.rowwise().sum())).asDiagonal();//*/

	//Repeated level of model 
	Matrix<double, 6, 6>  An_minus{
		{2*f_l*p1*mu1	  , 2*f_l*(1-p1)*mu1     , 0			     , 0					, 0						   , 0},
		{0				  , 0				     , f_l*mu1		     , 0					, 0						   , 0},
		{f_l*p1*p1*mu2	  , f_l*p1*(1-p1)*mu2    , f_l*(1-p1)*mu2    , 0					, 0						   , 0},
		{2*f_h*p_l*p1*mu1 , 2*f_h*p_l*(1-p1)*mu1 , 0			     , 2*f_h*(1-p_l)*p1*mu1 , 2*f_h*(1-p_l)*(1-p1)*mu1 , 0},
		{0				  , 0				     , f_h*p_l*mu1	     , 0					, 0						   , f_h*(1-p_l)*mu1},
		{f_h*p_l*p1*p1*mu2, f_h*p_l*p1*(1-p1)*mu2, f_h*p_l*(1-p1)*mu2, f_h*(1-p_l)*p1*p1*mu2, f_h*(1-p_l)*p1*(1-p1)*mu2, f_h*(1-p_l)*(1-p1)*mu2}};

	Matrix<double, 6, 6> An_0 = (-(An_minus.rowwise().sum() +
		A2_plus.rowwise().sum())).asDiagonal();

	QBD<double> process;

	process.add_zero_level(mMatr(A0_0), mMatr(A0_plus));
	process.add_level(mMatr(A1_minus), mMatr(A1_0), mMatr(A1_plus));
	//process.add_level((mMatr)A2_minus, (mMatr)A2_0, (mMatr)A2_plus);
	process.add_A_minus(mMatr(A2_minus));
	process.add_A_plus(mMatr(A2_plus));
	process.add_A_minus(An_minus);
	process.auto_A_0();

	StationaryDistribution<double> model;
	model.bind(process);

	// R computation test
	Matrix<double, Dynamic, Dynamic> Zero = model.get_R() * model.get_R() * An_minus + model.get_R() * An_0 + A2_plus;
	BOOST_CHECK(abs(Zero.minCoeff()) < 1e-15 && abs(Zero.maxCoeff()) < 1e-15);

	// G computation test
	Zero = An_minus + An_0 * model.get_G() + A2_plus * model.get_G() * model.get_G();
	BOOST_CHECK(abs(Zero.minCoeff()) < 1e-15 && abs(Zero.maxCoeff()) < 1e-15);

	
	// Idle probability test
	double idle = model.get_dist(0).back().sum();
	BOOST_CHECK(abs(idle - 0.5541908083815716423715) < 1e-15);
	
	// Mean clients test
	BOOST_CHECK(abs(model.get_mean_clients() - 0.7008368225019366848372) < 1e-15);
	
	// distributions tests
	double s = model.get_sum_from_c_to_inf().sum();
	BOOST_CHECK(abs(s - 0.1602374134784877446336) < 1e-15);

	auto dist = model.get_pi_0_c();
	for(unsigned int k = 0; k < dist.size() - 1; k++){
		s += dist[k].sum();
	}
	
	BOOST_CHECK(abs(s - 1) < 1e-15);

	// rho test
	BOOST_CHECK(abs(model.get_rho() - 0.4764904288174868218775) < 1e-15);

	// transient test
	double sim_up[215] = {0.1458791962543137810115, 0.2414490022933620250178, 0.3090319219835644393157, 0.3607736568884044592309, 0.4017745623879075411722, 0.4356865681565302850231,
			0.4643864351857485694985, 0.4899801908468052182855, 0.5105080024650140655851, 0.5293429206896577143837, 0.5459444157438742337263, 0.560681084565863629976, 
			0.5741276367139886982471, 0.5857181133685681606593, 0.5964474624811967329308, 0.6058964798581344401995, 0.6144875343050524296729, 0.6220633600394023243751, 
			0.6291554933376946046053, 0.6353437548729183870222, 0.6408842859217297460717, 0.646127331350784261943, 0.6508990887701598948567, 0.654858525964214233106, 
			0.6589405283456628570349, 0.6621831378130863532405, 0.6654340159509710694863, 0.6682276644291167411183, 0.6710763029812353286374, 0.6733287884775117637659,
			0.6756628283993446615341, 0.6778053574605624742588, 0.6797383039180497910081, 0.6813940915838666567694, 0.6829668400502538760932, 0.6843733447680251380518, 
			0.685498673155105264776, 0.6870093298002033499472, 0.6880684240148571273465, 0.6890328266458736194977, 0.6899545726205131845887, 0.6908917532636295044668, 
			0.6916447859244578832971, 0.6925629908218409180876, 0.6932869775883614416045, 0.6936340995076538673558, 0.6942138384786188387565, 0.6947493078552671175174, 
			0.6952584924221446582848, 0.6956937687163317063366, 0.6964307981015973592065, 0.6969126540377873491039, 0.6970957886304983697201, 0.6973895116056620935296, 
			0.697661655206741615487, 0.6978832235290393093408, 0.6982245770438159082616, 0.6984850542165962350438, 0.6986061467450430662041, 0.6989113676981992817616, 
			0.6990406504321008407388, 0.6992010886797743740573, 0.699274624298895308705, 0.6994095248559254462961, 0.6997731336947370373025, 0.6998643497698847637523, 
			0.7002152342744818458442, 0.7003520602067013767211, 0.7004924313110957312389, 0.7005928810251526028807, 0.7007841459436958686524, 0.700800531183157215942, 
			0.7009808322059668528325, 0.7006009809184421399664, 0.7011690230826209679904, 0.7008618156379525787614, 0.7009600534012537798034, 0.7010748092271583686852, 
			0.7008875403048130392492, 0.7008087169528623983084, 0.7007731406470085744331, 0.7009762265510032230864, 0.7012125390235789401672, 0.7012287865230359962254, 
			0.7011475691843065405351, 0.7012594828287402881628, 0.7009795076005556069276, 0.7011620911800640065792, 0.7010178945723125609746, 0.7012406232089128943485, 
			0.701708773471438229663, 0.7014892966046917255341, 0.7017654235349138902578, 0.7017186849768297651764, 0.7015975263529233840742, 0.7015389741322236583088, 
			0.7015218166879756411802, 0.7014279367016779120902, 0.7015789493829893697097, 0.7018342856667864060327, 0.701621226769802430745, 0.7017991035237938213243, 
			0.7018760973084263721233, 0.7021163353497860137864, 0.7019727062671122785886, 0.7018308552941808775572, 0.7019161140598664250234, 0.7020248058976461535963, 
			0.7020484768882165882431, 0.7020547479857950357029, 0.7019434926213958814145, 0.7018301942242001212335, 0.7017683187990340076823, 0.7021061675799449286473, 
			0.7021843697351862756406, 0.702323191990704587262, 0.7023083497971664979076, 0.7020028122636422507341, 0.7021632415019387618571, 0.7022812066862204050111, 
			0.7024239857981185997104, 0.7023634287982331025901, 0.702287156296344972084, 0.7023703422294703679896, 0.7023755567605945993037, 0.7018754871604597767032, 
			0.7021897863688397745108, 0.7021343188083980502157, 0.7019603182287817988438, 0.7021251682866019860896, 0.7021985729415446408908, 0.7021675360037014090864, 
			0.7023060146821369365, 0.7019129654471060186793, 0.7021326375836892674798, 0.702082440829373433111, 0.7019123686898203207107, 0.7020906578744717796425, 
			0.7018206904475824403633, 0.7019692481356339941456, 0.7019952849996804467025, 0.7020501055014101154939, 0.7023083873630089346562, 0.7023406510001212188499, 
			0.7022638109326464483928, 0.7020104253984903452945, 0.7019764855581333007351, 0.7018947006435026780835, 0.7015950095707895739494, 0.7015849097889635954672, 
			0.7018274922533462856222, 0.701783896352503044902, 0.7012944023701238593915, 0.7013265486873039300519, 0.7016936366071691022483, 0.7018084181654774544867,
			0.7018398641178085206604, 0.7018225717984220013435, 0.7017732059907142438959, 0.7017602888076237555026, 0.7018491439390662778308, 0.7016066734601822396655, 
			0.7016138555636919349467, 0.7016908454715251597378, 0.7018026684703833062429, 0.7020419847100545229779, 0.7022936354458236829501, 0.7024800894464831024777, 
			0.7022000582142124969209, 0.7020463118867190654981, 0.7022630144828276854696, 0.7024117068258343143938, 0.7019854446899869149235, 0.7020186863142118260939, 
			0.7018984417936295905349, 0.7020182482157117931365, 0.7020447270172178733105, 0.7022814666797716487423, 0.7024180399110270256458, 0.7025083230542593648593, 
			0.7023170274233221377358, 0.7025559732928040590494, 0.7024598346930162051649, 0.7022604902619433708821, 0.7022812933713233896071, 0.7022726000724527350982, 
			0.702395500493710800427, 0.7025186088089679925517, 0.7025992705434772611639, 0.7026606442354708104148, 0.7026396214134288387143, 0.7023965319896202652572, 
			0.7021978875943414299954, 0.702197831929044058441, 0.7023273786870629642465, 0.7023119790017082753053, 0.7024809080194585053647, 0.7025017768974420873107, 
			0.7022964665646239668106, 0.702296932452383781964, 0.7024184182120599695409, 0.70217505847616024095, 0.7023838655875318526256, 0.7023123008197615924075, 
			0.7022621110753384243708, 0.7019092830541369121278, 0.7018014999948716248213, 0.7016127835068288742804, 0.7016766452120517527646, 0.7016677381925960910181, 
			0.701906630012887444714, 0.7023351786480298564186, 0.7020512210678908626704, 0.7023220788795305757901, 0.7022901755232098253146};
	double sim_down[215] = {0.1451290037516408393259, 0.2404717977177693866153, 0.3079124780311993658799, 0.3595499431291219183393, 0.4004694376317857740233, 
			0.4343136318649550853266, 0.462956564837235851062, 0.4885008091774629681581, 0.5089843975543050456523, 0.5277804793188342058485, 0.5443477842557893684017, 
			0.559052715425932156279, 0.572471163270935168299, 0.5840364866107247143745, 0.5947423374928825223762, 0.6041701201115853292478, 0.6127420656607274196404, 
			0.6203004399229308241104, 0.6273765066214671559663, 0.6335498450837078188158, 0.6390767140324277173491, 0.6443074686010816787274, 0.6490677111797650278291, 
			0.6530166739841810619183, 0.6570884716010809700748, 0.6603226621323708966926, 0.6635657839931505819209, 0.6663513355140155969281, 0.6691926969607774333682, 
			0.6714386114635394475769, 0.6737665715407732403008, 0.6759036424786948327181, 0.6778308960205599031923, 0.6794821083539591688449, 0.6810501598870711825739, 
			0.6824524551687680684608, 0.6835739267812089847709, 0.6850806701355116601349, 0.6861365759206070613629, 0.6870979732892257274557, 0.6880166273142667154872, 
			0.688951046670806754868, 0.6897016140097103065187, 0.6906182091119976718119, 0.6913394223451090336852, 0.6916851004256693302708, 0.6922635614544828674966, 
			0.6927966920776638115598, 0.6933047075106674173028, 0.6937386312161851753544, 0.6944736018306854052895, 0.6949539458944550274211, 0.6951356113016221582868, 
			0.6954280883262846657544, 0.6956991447250817639514, 0.6959201764027749259611, 0.6962600228878713659597, 0.6965199457149578998738, 0.696640253186513236372, 
			0.6969442322332266570584, 0.6970727494992171591193, 0.6972325112515072031982, 0.6973053756324011365209, 0.6974392750753178882306, 0.6978022662362721728613, 
			0.6978926501611329991093, 0.6982431656564958011302, 0.698379339724185865812, 0.6985191686198143345976, 0.6986195189056246812598, 0.6988102539869993634625, 
			0.698826268747529621983, 0.6990065677246070086071, 0.6986268190123687826798, 0.6991937768480144255179, 0.6988859842928328847123, 0.6989841465295963951476, 
			0.6990987907035814963308, 0.6989122596258349195963, 0.6988334829779275780837, 0.6987976592837454870022, 0.6990001733796257221698, 0.6992360609068860588522, 
			0.6992522134075389583785, 0.6991710307462677409518, 0.699282717101835760154, 0.6990032923301390255233, 0.6991857087505159995544, 0.6990417053584244699849, 
			0.6992633767218158213907, 0.6997312264590009878162, 0.6995119033259691310178, 0.6997877763956265040335, 0.6997411149537402508258, 0.6996200735776058055038, 
			0.6995616257982869568011, 0.6995447832425577550097, 0.699451063228946234851, 0.6996016505475766145139, 0.6998559142637780228213, 0.699642773160866870974, 
			0.6998204964065624089642, 0.699897102621915845333, 0.7001372645804732064434, 0.6999938936633346431293, 0.6998521446364024400921, 0.6999372858705319444539, 
			0.7000453940326625268398, 0.7000691230421581812138, 0.7000748519444901507569, 0.6999635073088326109314, 0.6998502057062009340527, 0.6997884811315338016158, 
			0.7001260323504501226211, 0.7002038301952332455258, 0.7003424079395240697821, 0.7003284501330904188166, 0.7000231876668830954813, 0.7001833584283050360142, 
			0.7003011932439903164394, 0.7004440141321831569954, 0.7003829711321453155293, 0.7003076436338367960488, 0.7003906577007857903183, 0.7003954431696118865247, 
			0.6998959127699875271134, 0.7002100135614433007447, 0.7001548811219949763895, 0.6999810817016750563724, 0.7001460316437758679697, 0.7002192269887851372445, 
			0.7001880639267181738461, 0.700326385248125626859, 0.6999340344831740390319, 0.7001533623466821287806, 0.7001023591010747670893, 0.6999326312406728423099, 
			0.7001111420559186226953, 0.6998411094828623779662, 0.6999897517947798464277, 0.7000161149307151386978, 0.7000704944290452313993, 0.7003286125672114614815, 
			0.7003605489301721886974, 0.7002837889975914720253, 0.7000311745319044431923, 0.699997314372103995872, 0.6999158992868420581246, 0.699616390359704021229, 
			0.6996062901415786017267, 0.6998485076771521207206, 0.6998051035778868333992, 0.6993163975604458348911, 0.6993484512433627564576, 0.6997155633232698956903, 
			0.6998301817650699474527, 0.6998619358125945932869, 0.6998452281319341716781, 0.6997955939396478530767, 0.6997829111227589216071, 0.6998718559912852077431, 
			0.6996291264703498047339, 0.699636544366725843247, 0.699713754458846981521, 0.6998249314601443504813, 0.7000642152202183332577, 0.7003155644843627181118, 
			0.7005015104836327388682, 0.7002217417159848356079, 0.7000680880434673181156, 0.7002841854474526339658, 0.7004326931044168036422, 0.7000069552404497574827, 
			0.7000391136162417149436, 0.6999189581369051893489, 0.7000383517146289147348, 0.7000646729131370094024, 0.7003011332503965569174, 0.7004373600191978743723, 
			0.700527276875870685835, 0.7003361725068495413637, 0.7005750266372531287473, 0.7004787652371597950207, 0.7002799096683831603372, 0.7003001065587513007671, 
			0.7002913998577035004089, 0.7004140994365302130831, 0.7005375911211121353617, 0.7006187293866054099922, 0.7006801556945447817526, 0.7006591785165908747857, 
			0.7004166679407565210269, 0.7002181123360730063965, 0.700218168001343288509, 0.7003478212432889815631, 0.7003320209285754938122, 0.7005008919106991971404, 
			0.700521623032753892879, 0.7003161333657020870547, 0.7003164674779880360944, 0.7004379817181681788796, 0.7001955414542532230016, 0.7004043343428110190985, 
			0.7003326991105534027326, 0.7002826888548883133012, 0.6999303168764297033988, 0.6998224999358120257398, 0.6996344164239354235235, 0.6996985547186302945022, 
			0.6996898617380536977706, 0.6999287699176620636266, 0.7003570212822758378479, 0.700073378862502426756, 0.7003429210507907676231, 0.7003110244072008327976};

	// Taylor series method of 15 order:
	TaylorSeriesTransient<double> trans;
	trans.bind(process, 15);
	// Initial condition
	std::vector<Eigen::VectorX<double>> pi_0;
	Eigen::VectorX<double> pi_00 = Eigen::VectorX<double>::Zero(2);
	pi_00(0) = 0.5;
	pi_00(1) = 0.5;
	pi_0.push_back(pi_00);
	// computate clients:
	vector<double> clients = trans.get_mean_clients(40, pi_0);
	bool transient_result = true;
	for(uint_fast8_t k = 0; k < 215; k++){
		transient_result = transient_result && ((sim_down[k] < clients[k + 1]) && (clients[k + 1] < sim_up[k]));
	}
	BOOST_CHECK(transient_result);
}

BOOST_AUTO_TEST_CASE(M_M_1_model)
{
	double l = 2;
	double m = 3;
	double rho = l/m;
	Matrix<double, 1, 1> lambda{{l}};
	Matrix<double, 1, 1> mu{{m}};

	QBD<double> process;
	StationaryDistribution<double> model;

	//process.add_zero_level((mMatr)(-lambda), (mMatr)lambda);
	//process.add_level((mMatr)mu,(mMatr)(-lambda - mu),(mMatr)lambda);
	//process.add_level((mMatr)mu,(mMatr)(-lambda - mu),(mMatr)lambda);
	// Zero level:
	process.add_A_plus(mMatr(lambda));
	// c level:
	process.add_A_plus(mMatr(lambda));
	process.add_A_minus(mMatr(mu));
	// c+1 level:
	process.add_A_minus(mMatr(mu));
	process.add_A_plus(mMatr(lambda));
	process.auto_A_0();
	model.bind(process);
	// Test for memory operations. Add -fsanitize=address
	Q_in_pow<double> test(process);
	//test.print();
	Q_in_pow<double> t2 = test.inc_power(1);
	//t2.print();

	BOOST_CHECK(abs(model.get_mean_clients() - rho/(1-rho)) <= 3e-15);
	//cout << abs(model.get_mean_clients() - rho/(1-rho)) << endl;

	vector<VectorX<double>> queue;
	VectorX<double> q0{{0}};
	VectorX<double> q1{{0}};
	queue.push_back(q0);
	queue.push_back(q1);

	//cout << abs(model.get_mean_queue(queue) - rho*rho/(1 - rho)) << endl;
	BOOST_CHECK(abs(model.get_mean_queue(queue) - rho*rho/(1 - rho)) < 2e-15);
	//cout << abs(model.get_mean_queue(queue) - rho*rho/(1 - rho))<< endl;

	BOOST_CHECK(abs(model.get_R()(0,0) - rho) < 1e-15);
	//cout << abs(model.get_R()(0,0) - rho) << endl;
	BOOST_CHECK(abs(model.get_rho() - rho) < 1e-15);
	//cout << abs(model.get_rho() - rho) << endl;
}
